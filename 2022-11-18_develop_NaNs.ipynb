{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5746ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from scipy import linalg, io\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b70225",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARGES_LIST_QM9 = [1, 6, 7, 8, 9]\n",
    "CHARGES_LIST_QM7 = [1, 6, 7, 8, 16]\n",
    "\n",
    "class PointCloudMoleculeDataSet(Dataset):\n",
    "    def __init__(self, coords_cart: np.ndarray, charges: np.ndarray, energies: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        coords_cart has shape (n_samples, max_n_atoms, 3)\n",
    "        charges has shape (n_samples, max_n_atoms)\n",
    "        energies has shape (n_samples,)\n",
    "        \"\"\"\n",
    "        # print(charges.shape)\n",
    "        self._coords_cart = coords_cart\n",
    "        self._charges = charges\n",
    "        self.n_samples = self._coords_cart.shape[0]\n",
    "        self.n_atoms = np.sum(charges != 0, axis=1)\n",
    "        # print(self.n_atoms.shape)\n",
    "        self.energies = energies\n",
    "        self.coords_aligned = None\n",
    "        self.one_hot_point_features = None\n",
    "        self.U_matrices = None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        coords_out = self.coords_aligned[index, :self.n_atoms[index]]\n",
    "        charge_features_out = self.one_hot_point_features[index, :self.n_atoms[index]]\n",
    "        energies_out = self.energies[index]\n",
    "        return (coords_out, charge_features_out, energies_out)\n",
    "\n",
    "    def align_coords_cart(self) -> None:\n",
    "        out = np.full_like(self._coords_cart, np.nan)\n",
    "        out_U_mats = np.zeros((self.n_samples, 3, 3))\n",
    "\n",
    "        for i in range(self.n_samples):\n",
    "            n_atoms_i = self.n_atoms[i]\n",
    "            coords_i = self._coords_cart[i, :n_atoms_i]\n",
    "            coords_i = coords_i - np.mean(coords_i, axis=0)\n",
    "            U, _, _ = linalg.svd(coords_i.transpose(), full_matrices=False)\n",
    "            coords_aligned = np.matmul(U.transpose(), coords_i.transpose()).transpose()\n",
    "            out[i, :n_atoms_i] = coords_aligned\n",
    "            out_U_mats[i] = U\n",
    "\n",
    "        self.coords_aligned = torch.Tensor(out)\n",
    "        self.U_matrices = torch.Tensor(out_U_mats)\n",
    "        \n",
    "\n",
    "    def charges_to_one_hot_QM7(self) -> None:\n",
    "        out = np.full((self.n_samples, \n",
    "                        self._charges.shape[1], \n",
    "                        len(CHARGES_LIST_QM7)), np.nan)\n",
    "        charges_lst = CHARGES_LIST_QM7\n",
    "        charges_lst_arr = np.array(CHARGES_LIST_QM7)\n",
    "        for i in range(self.n_samples):\n",
    "            n_atoms_i = self.n_atoms[i]\n",
    "            out[i, :n_atoms_i] = np.zeros_like(out[i, :n_atoms_i])\n",
    "            charges_i = self._charges[i, :n_atoms_i]\n",
    "            col_idxes = [charges_lst.index(x) for x in charges_i]\n",
    "            for atom_idx, charge_col_idx in enumerate(col_idxes):\n",
    "                out[i, atom_idx, charge_col_idx] = 1.\n",
    "        self.one_hot_point_features = torch.Tensor(out)\n",
    "\n",
    "    def charges_to_one_hot_QM9(self) -> None:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938dee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_charges_to_one_hot() -> None:\n",
    "    \n",
    "    coords = np.full((2, 5, 3), np.nan)\n",
    "    coords[0, :4] = np.random.normal(size=(4, 3))\n",
    "    coords[1, :3] = np.random.normal(size=(3, 3))\n",
    "    charges = np.array([[1, 1, 6, 6, 0],\n",
    "                        [7, 7, 1, 0, 0]])\n",
    "    \n",
    "    energies = np.random.normal(size=2)\n",
    "    \n",
    "    x = PointCloudMoleculeDataSet(coords, charges, energies)\n",
    "    \n",
    "    x.align_coords_cart()\n",
    "    x.charges_to_one_hot_QM7()\n",
    "    \n",
    "    expected_one_hot_encoding = np.full((charges.shape[0], charges.shape[1], len(CHARGES_LIST_QM7)), np.nan)\n",
    "    expected_one_hot_encoding[0, :4] = np.array([[1, 0, 0, 0, 0],\n",
    "                                                [1, 0, 0, 0, 0],\n",
    "                                                [0, 1, 0, 0, 0],\n",
    "                                                [0, 1, 0, 0, 0]])\n",
    "    expected_one_hot_encoding[1, :3] = np.array([[0, 0, 1, 0, 0],\n",
    "                                                [0, 0, 1, 0, 0],\n",
    "                                                [1, 0, 0, 0, 0]])\n",
    "    assert np.allclose(x.one_hot_point_features, \n",
    "                       expected_one_hot_encoding, equal_nan=True), \"{}, {}\".format(x.one_hot_point_features[1].numpy(),\n",
    "                                                                expected_one_hot_encoding[1])\n",
    "    \n",
    "test_charges_to_one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "783a8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz: torch.Tensor, npoint: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Uses a farthest point sampling scheme to downsample the point cloud\n",
    "    Input:\n",
    "        xyz (torch.Tensor): pointcloud data, has shape [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, which has shape [B, npoint]\n",
    "    \"\"\"\n",
    "    print(xyz)\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    # List of random integers in [0, N] with length B\n",
    "#     farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device) \n",
    "    \n",
    "    # Prevent the initial choice from being a NaNed Out Row\n",
    "    n_points_in_cloud = torch.sum(torch.logical_not(torch.isnan(xyz[:, :, 0])), axis=1)\n",
    "#     print(\"N_POINTS\", n_points_in_cloud)\n",
    "    rand_draws = torch.rand(size=(B,)).to(device)\n",
    "#     print(\"RAND DRAWS\", rand_draws)\n",
    "    scaled_rand_draws = torch.mul(n_points_in_cloud, rand_draws)\n",
    "#     print(\"SCALED R\", scaled_rand_draws)\n",
    "    farthest = torch.floor(scaled_rand_draws).type(torch.long)\n",
    "#     print(\"FARTHEST\", farthest)\n",
    "#     print([x.data for x in n_points_in_cloud])\n",
    "#     farthest = torch.Tensor([torch.randint(0, x.data, dtype=torch.long) for x in n_points_in_cloud]).to(device)\n",
    "    \n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        # Start with the random indices in the 0th column.\n",
    "        centroids[:, i] = farthest\n",
    "        \n",
    "        # The centroid thing has one xyz location for each element in the batch\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        \n",
    "        # Dist finds distance squared between each XYZ point and the centroid\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "#         print(\"DIST\", dist)\n",
    "        mask = dist < distance\n",
    "        mask += torch.isnan(dist)\n",
    "        distance[mask] = torch.nan_to_num(dist[mask]) # Caps distances at 1e10\n",
    "#         print(\"DISTANCE\", distance)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f33d28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points: torch.Tensor, idx: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S]\n",
    "    Return:\n",
    "        new_points: The subsampeled points [B, S, C]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zmï¼›\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def query_ball_point(radius: float, \n",
    "                        nsample: int, \n",
    "                        xyz: torch.Tensor, \n",
    "                        query_centroids: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This function takes in a set of centroids <query_centroids> and finds the <nsample>\n",
    "    points in <xyz> that are closest to the centroids AND are within <radius> from the centroid.\n",
    "    \n",
    "    IF there are not enough points in <xyz> to satisfy the above sampling requirements, this \n",
    "    function returns the indexes of all of the points inside <xyz> that do satisfy the radius\n",
    "    requirements and pads the index array with the index of the query centroid.\n",
    "    \n",
    "    Input:\n",
    "        radius (float): local region radius\n",
    "        nsample (int): max sample number in local region. MUST BE SMALLER THAN N\n",
    "        xyz (torch.Tensor): all points, [B, N, 3]\n",
    "        query_centroids (torch.Tensor): query points, [B, S, 3]\n",
    "    Return:\n",
    "        group_idx: grouped points index, [B, S, nsample]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    _, S, _ = query_centroids.shape\n",
    "\n",
    "    group_idx = torch.arange(N, \n",
    "                             dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1]) # Shape [B, S, N]\n",
    "    print(\"GROUP_IDX\", group_idx)\n",
    "    sqrdists = square_distance(query_centroids, xyz) # Shape [B, S, N]\n",
    "    print(\"DIST\", sqrdists)\n",
    "    idxes_sorted_dists = torch.argsort(sqrdists, dim=-1)\n",
    "    print(\"INDEXSORTDIST\", idxes_sorted_dists, idxes_sorted_dists.shape)\n",
    "    print(\"IDX\", idxes_sorted_dists[:, :, 0])\n",
    "    points_for_sampling = xyz.view(B, 1, N, C).repeat([1, S, 1, 1])\n",
    "    print(\"POITNS\", points_for_sampling)\n",
    "#     return\n",
    "    closest_points = points_for_sampling[:, idxes_sorted_dists[:, :, 0]]\n",
    "    print(\"CLOSEST_POINTS\", closest_points)\n",
    "    return\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    print(\"GROUP_IDX 1\", group_idx)\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    print(\"GROUP_IDX 2\", group_idx)\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
    "    print(\"GROUP FIRST\", group_first)\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    print(\"OUT\", group_idx)\n",
    "    \n",
    "    return group_idx\n",
    "\n",
    "def query_ball_point_no_batch(radius: float,\n",
    "                             n_sample: int,\n",
    "                             xyz: torch.Tensor,\n",
    "                             query_centroids: torch.Tensor,\n",
    "                             query_centroid_idxes: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    N, C = xyz.shape\n",
    "    S, _ = query_centroids.shape\n",
    "    \n",
    "    # First, find the pairwise distances between the xyz points and \n",
    "    # the query centroids\n",
    "    out_distances = square_distance(xyz.view([1, N, C]), query_centroids.view([1, S, C])).view([N, S])\n",
    "    print(out_distances)\n",
    "    print(out_distances.shape)\n",
    "    nearest_indexes = torch.argsort(out_distances, dim=0)\n",
    "    print(nearest_indexes)\n",
    "    sorted_dist = out_distances[nearest_indexes]\n",
    "    print(nearest_indexes.shape, sorted_dist.shape)\n",
    "    # Then, use the indexes of the query centroid points to seed the \n",
    "    # output array\n",
    "    out_arr = query_centroid_idxes.view([S, 1]).repeat([1, n_sample])\n",
    "    print(out_arr)\n",
    "    \n",
    "    # Mask by the radius condition\n",
    "    \n",
    "    radius_mask = sorted_dist > radius ** 2\n",
    "    print(radius_mask)\n",
    "    print(radius_mask.shape)\n",
    "    \n",
    "    # Output the masked indexes\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c918e16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100., 400.],\n",
      "        [ 81., 361.],\n",
      "        [ 64., 324.],\n",
      "        [ 49., 289.],\n",
      "        [ 36., 256.],\n",
      "        [  0., 100.],\n",
      "        [100.,   0.]])\n",
      "torch.Size([7, 2])\n",
      "tensor([[5, 6],\n",
      "        [4, 5],\n",
      "        [3, 4],\n",
      "        [2, 3],\n",
      "        [1, 2],\n",
      "        [0, 1],\n",
      "        [6, 0]])\n",
      "torch.Size([7, 2]) torch.Size([7, 2, 2])\n",
      "tensor([[5, 5, 5, 5],\n",
      "        [6, 6, 6, 6]])\n",
      "tensor([[[False,  True],\n",
      "         [ True, False]],\n",
      "\n",
      "        [[ True,  True],\n",
      "         [False,  True]],\n",
      "\n",
      "        [[ True,  True],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True,  True],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True,  True],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True,  True],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True, False],\n",
      "         [ True,  True]]])\n",
      "torch.Size([7, 2, 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "allclose(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [77], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     expected_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(out, expected_out)    \n\u001b[0;32m---> 21\u001b[0m \u001b[43mtest_query_ball_point_no_sampling_behavior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [77], line 20\u001b[0m, in \u001b[0;36mtest_query_ball_point_no_sampling_behavior\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m out \u001b[38;5;241m=\u001b[39m query_ball_point_no_batch(\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m4\u001b[39m, in_xyz, in_query_points, in_query_idxes)\n\u001b[1;32m     19\u001b[0m expected_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_out\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: allclose(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "def test_query_ball_point_no_sampling_behavior() -> None:\n",
    "    \"\"\"\n",
    "    Tests that the query_ball_point function returns the correct number of \n",
    "    points when there are no points for subsampling\n",
    "    \"\"\"\n",
    "    in_xyz = torch.Tensor([[0, 0, 0],\n",
    "                            [1, 0, 0],\n",
    "                            [2, 0, 0],\n",
    "                            [3, 0, 0],\n",
    "                            [4, 0, 0],\n",
    "                            [10, 0, 0],\n",
    "                            [20, 0, 0]])\n",
    "    in_query_points = torch.Tensor([[10, 0, 0], [20, 0, 0]])\n",
    "    \n",
    "    in_query_idxes = torch.Tensor([5, 6]).type(torch.long)\n",
    "    \n",
    "    \n",
    "    out = query_ball_point_no_batch(1., 4, in_xyz, in_query_points, in_query_idxes)\n",
    "    expected_out = torch.Tensor([1, 0, 2, 1]).type(torch.long)\n",
    "    assert torch.allclose(out, expected_out)    \n",
    "test_query_ball_point_no_sampling_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "454c991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUP_IDX tensor([[[0, 1, 2, 3, 4]]])\n",
      "DIST tensor([[[1., 0., 1., 4., 9.]]])\n",
      "INDEXSORTDIST tensor([[[1, 0, 2, 3, 4]]])\n",
      "GROUP_IDX 1 tensor([[[0, 1, 2, 5, 5]]])\n",
      "GROUP_IDX 2 tensor([[[0, 1, 2, 5]]])\n",
      "GROUP FIRST tensor([[[0, 0, 0, 0]]])\n",
      "GROUP_IDX 3 tensor([[[0, 1, 2, 0]]])\n"
     ]
    }
   ],
   "source": [
    "def test_query_ball_point_undersampling_behavior() -> None:\n",
    "    \"\"\"\n",
    "    Tests that the query_ball_point function returns the correct number of \n",
    "    points when there are not enough points for subsampling\n",
    "    \"\"\"\n",
    "    in_xyz = torch.Tensor([[[0, 0, 0],\n",
    "                            [1, 0, 0],\n",
    "                            [2, 0, 0],\n",
    "                            [3, 0, 0],\n",
    "                            [4, 0, 0]]])\n",
    "    in_new_xyz = torch.Tensor([[[1, 0, 0]]])\n",
    "    \n",
    "    out = query_ball_point(1., 4, in_xyz, in_new_xyz)\n",
    "    expected_out = torch.Tensor([[1, 0, 2, 1]]).type(torch.long)\n",
    "    assert torch.allclose(out, expected_out)    \n",
    "test_query_ball_point_undersampling_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31163049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query_ball_point_2() -> None:\n",
    "    \"\"\"\n",
    "    Tests that the query_ball_point function returns the correct number of \n",
    "    points when there are not enough points for subsampling\n",
    "    \"\"\"\n",
    "    in_xyz = torch.Tensor([[[0, 0, 0],\n",
    "                            [1, 0, 0],\n",
    "                            [2, 0, 0],\n",
    "                            [3, 0, 0],\n",
    "                            [4, 0, 0]]])\n",
    "    in_new_xyz = torch.Tensor([[[0, 0, 0]]])\n",
    "    \n",
    "    out = query_ball_point(1., 3, in_xyz, in_new_xyz)\n",
    "#     expected_out = torch.Tensor([[0, 1]]).type(torch.long)\n",
    "#     assert torch.allclose(out, expected_out)    \n",
    "test_query_ball_point_2()\n",
    "\n",
    "def test_query_ball_point_1() -> None:\n",
    "    \"\"\"\n",
    "    Tests that the query_ball_point function returns the correct number of \n",
    "    points when there are more than enough points for subsampling\n",
    "    \"\"\"\n",
    "    in_xyz = torch.Tensor([[[0, 0, 0],\n",
    "                            [1, 0, 0],\n",
    "                            [2, 0, 0],\n",
    "                            [3, 0, 0],\n",
    "                            [4, 0, 0]]])\n",
    "    in_new_xyz = torch.Tensor([[[0, 0, 0]]])\n",
    "    \n",
    "    out = query_ball_point(3., 2, in_xyz, in_new_xyz)\n",
    "    expected_out = torch.Tensor([[0, 1]]).type(torch.long)\n",
    "    assert torch.allclose(out, expected_out)    \n",
    "test_query_ball_point_1()\n",
    "\n",
    "def test_query_ball_point_0() -> None:\n",
    "    \"\"\"\n",
    "    Tests that the query_ball_point function runs without error\n",
    "    \"\"\"\n",
    "    in_xyz = torch.Tensor([[[0, 0, 0],\n",
    "                            [1, 0, 0],\n",
    "                            [2, 0, 0],\n",
    "                            [3, 0, 0],\n",
    "                            [4, 0, 0]]])\n",
    "    in_new_xyz = torch.Tensor([[[0, 0, 0]]])\n",
    "    \n",
    "    out = query_ball_point(1., 2, in_xyz, in_new_xyz)\n",
    "#     print(out)\n",
    "    \n",
    "#     newly_indexed_points = index_points(in_xyz, out)\n",
    "#     print(newly_indexed_points)\n",
    "    \n",
    "test_query_ball_point_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd081036",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_xyz_arr = np.full((2, 7, 3), np.nan)\n",
    "in_xyz_arr[0, :6] = np.random.normal(size=(6, 3))\n",
    "in_xyz_arr[1, :5] = np.random.normal(size=(5, 3))\n",
    "\n",
    "in_tensor = torch.Tensor(in_xyz_arr)\n",
    "# in_t = torch.Tensor(in_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5b87b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "tensor([[[0.0000, 0.0000, 1.0000],\n",
      "         [0.0000, 0.0000, 1.1000],\n",
      "         [1.0000, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan]]])\n",
      "N_POINTS tensor([3])\n",
      "RAND DRAWS tensor([0.2754])\n",
      "SCALED R tensor([0.8261])\n",
      "FURTHEST tensor([0])\n",
      "DIST tensor([[0.0000, 0.0100, 2.0000,    nan]])\n",
      "DISTANCE tensor([[0.0000, 0.0100, 2.0000, 0.0000]])\n",
      "DIST tensor([[2.0000, 2.2100, 0.0000,    nan]])\n",
      "DISTANCE tensor([[0.0000, 0.0100, 0.0000, 0.0000]])\n",
      "OUT tensor([[0, 2]])\n",
      "OUT tensor([[0, 2]])\n"
     ]
    }
   ],
   "source": [
    "def test_FPS_simple_input_with_nans() -> None:\n",
    "    in_arr = np.array([[[0, 0, 1], # 0\n",
    "                       [0, 0, 1.1], # 1\n",
    "                       [1, 0, 0], # 2\n",
    "                       [np.nan, np.nan, np.nan]]]) # 3\n",
    "    in_tensor = torch.Tensor(in_arr)\n",
    "    print(in_tensor.shape)\n",
    "    out = farthest_point_sample(in_tensor, 2)\n",
    "    print(\"OUT\", out)\n",
    "    if out[0, 0] in [0, 1]:\n",
    "        assert out[0, 1] == 2\n",
    "    else:\n",
    "        assert out[0, 1] == 1\n",
    "    return out\n",
    "out = test_FPS_simple_input_with_nans()\n",
    "print(\"OUT\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bea89922",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.sum(torch.logical_not(torch.isnan(in_tensor[:, :, 0])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f7a19196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "67d4c02b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint(): argument 'high' (position 1) must be int, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint(): argument 'high' (position 1) must be int, not Tensor"
     ]
    }
   ],
   "source": [
    "torch.randint(torch.zeros_like(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcd66604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIST tensor([[2.0000, 2.2100, 0.0000, 0.0100]])\n",
      "DISTANCE tensor([[2.0000, 2.2100, 0.0000, 0.0100]])\n",
      "torch.return_types.max(\n",
      "values=tensor([2.2100]),\n",
      "indices=tensor([1]))\n",
      "DIST tensor([[0.0100, 0.0000, 2.2100, 2.4200]])\n",
      "DISTANCE tensor([[0.0100, 0.0000, 0.0000, 0.0100]])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0100]),\n",
      "indices=tensor([0]))\n",
      "OUT tensor([[2, 1]])\n"
     ]
    }
   ],
   "source": [
    "def test_FPS_simple_input() -> None:\n",
    "    in_arr = np.array([[[0, 0, 1], # 0\n",
    "                       [0, 0, 1.1], # 1\n",
    "                       [1, 0, 0], # 2\n",
    "                       [1.1, 0, 0]]]) # 3\n",
    "    in_tensor = torch.Tensor(in_arr)\n",
    "    out = farthest_point_sample(in_tensor, 2)\n",
    "    \n",
    "    if out[0, 0] in [2, 3]:\n",
    "        assert out[0, 1] == 1\n",
    "    else:\n",
    "        assert out[0, 1] == 3\n",
    "#     return out\n",
    "out = test_FPS_simple_input()\n",
    "print(\"OUT\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e37d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea9cd2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8269, 3.2433, 4.1188, 7.2420, 0.0000, 8.7664,    nan],\n",
      "        [   nan,    nan,    nan,    nan,    nan,    nan,    nan]])\n",
      "tensor([[2.8269, 3.2433, 4.1188, 7.2420, 0.0000, 8.7664,    nan],\n",
      "        [   nan,    nan,    nan,    nan,    nan,    nan,    nan]])\n",
      "tensor([[   nan,    nan,    nan,    nan,    nan,    nan,    nan],\n",
      "        [0.0000, 3.7153, 4.2614, 7.8100, 4.8693,    nan,    nan]])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan]])\n",
      "tensor([[4, 6],\n",
      "        [6, 0]])\n",
      "tensor([4, 6])\n",
      "tensor([6, 0])\n"
     ]
    }
   ],
   "source": [
    "def test_FPS_input_NaNs() -> None:\n",
    "    \"\"\"\n",
    "    Tests that inputting NaNs responds in well-defined behavior for\n",
    "    the furthest_point_sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    in_xyz_arr = np.full((2, 7, 3), np.nan)\n",
    "    in_xyz_arr[0, :6] = np.random.normal(size=(6, 3))\n",
    "    in_xyz_arr[1, :5] = np.random.normal(size=(5, 3))\n",
    "    \n",
    "    in_tensor = torch.Tensor(in_xyz_arr)\n",
    "    \n",
    "    out = farthest_point_sample(in_tensor, 2)\n",
    "    return out\n",
    "\n",
    "out = test_FPS_input_NaNs()\n",
    "\n",
    "print(out)\n",
    "print(out[0])\n",
    "print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f421cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
